{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "great-garlic",
   "metadata": {},
   "source": [
    "# CAPEC Data Analysis\n",
    "__Ivan Ulloa - 1/29/2021__\n",
    "\n",
    "- This nootebok imports an xml file containing CAPEC information.<br>\n",
    "- The 4 fields used are ID, Description, Relations to other attacks and Relations to CWE.<br>\n",
    "- The resulting descriptions are stored in CAPEC.txt to further process using Autophrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "specified-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import xmltodict\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-aviation",
   "metadata": {},
   "source": [
    "##  Load CAPEC dataset and save to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "medium-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse('data/1000.xml')\n",
    "xml_data = tree.getroot()\n",
    "# Change the encoding type to be able to set it to the one you need\n",
    "xmlstr = ET.tostring(xml_data, encoding='utf-8', method='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prescription-static",
   "metadata": {},
   "outputs": [],
   "source": [
    "capec = xmltodict.parse(xmlstr)\n",
    "with open('data/capec_data.json', 'w') as f:\n",
    "    f.write(json.dumps(capec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "blessed-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = dict(xmltodict.parse(xmlstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "chronic-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract ID, Descriptions, CAPEC relationships, and CWE Relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "printable-anthropology",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ID = []\n",
    "Desc = []\n",
    "Rel_CAPEC = []\n",
    "Rel_CWE = []\n",
    "for i in range(len(capec['ns0:Attack_Pattern_Catalog']['ns0:Attack_Patterns']['ns0:Attack_Pattern'])):\n",
    "    ID.append(capec['ns0:Attack_Pattern_Catalog']['ns0:Attack_Patterns']['ns0:Attack_Pattern'][i]['@ID'])\n",
    "    Desc.append(capec['ns0:Attack_Pattern_Catalog']['ns0:Attack_Patterns']['ns0:Attack_Pattern'][i]['ns0:Description'])\n",
    "    try:\n",
    "        Rel_CAPEC.append(capec['ns0:Attack_Pattern_Catalog']['ns0:Attack_Patterns']['ns0:Attack_Pattern'][i]['ns0:Related_Attack_Patterns']['ns0:Related_Attack_Pattern'])\n",
    "    except:\n",
    "        Rel_CAPEC.append('None')\n",
    "    try:\n",
    "        Rel_CWE.append(capec['ns0:Attack_Pattern_Catalog']['ns0:Attack_Patterns']['ns0:Attack_Pattern'][i]['ns0:Related_Weaknesses']['ns0:Related_Weakness'])\n",
    "    except:\n",
    "        Rel_CWE.append('None')\n",
    "dict = {'ID': ID, 'Description': Desc, 'rel_CAPEC':Rel_CAPEC, 'rel_CWE':Rel_CWE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "distant-charleston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Description</th>\n",
       "      <th>rel_CAPEC</th>\n",
       "      <th>rel_CWE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>In applications, particularly web applications...</td>\n",
       "      <td>[{'@CAPEC_ID': '122', '@Nature': 'ChildOf'}, {...</td>\n",
       "      <td>[{'@CWE_ID': '276'}, {'@CWE_ID': '285'}, {'@CW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>This attack pattern involves causing a buffer ...</td>\n",
       "      <td>{'@CAPEC_ID': '100', '@Nature': 'ChildOf'}</td>\n",
       "      <td>[{'@CWE_ID': '120'}, {'@CWE_ID': '302'}, {'@CW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>Buffer Overflow attacks target improper or mis...</td>\n",
       "      <td>{'@CAPEC_ID': '123', '@Nature': 'ChildOf'}</td>\n",
       "      <td>[{'@CWE_ID': '120'}, {'@CWE_ID': '119'}, {'@CW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>An attacker can use Server Side Include (SSI) ...</td>\n",
       "      <td>{'@CAPEC_ID': '253', '@Nature': 'ChildOf'}</td>\n",
       "      <td>[{'@CWE_ID': '97'}, {'@CWE_ID': '74'}, {'@CWE_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>Session sidejacking takes advantage of an unen...</td>\n",
       "      <td>{'@CAPEC_ID': '593', '@Nature': 'ChildOf'}</td>\n",
       "      <td>[{'@CWE_ID': '294'}, {'@CWE_ID': '522'}, {'@CW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>94</td>\n",
       "      <td>This type of attack targets the communication ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'@CWE_ID': '300'}, {'@CWE_ID': '290'}, {'@CW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>95</td>\n",
       "      <td>This attack targets the WSDL interface made av...</td>\n",
       "      <td>{'@CAPEC_ID': '54', '@Nature': 'ChildOf'}</td>\n",
       "      <td>{'@CWE_ID': '538'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>96</td>\n",
       "      <td>An application typically makes calls to functi...</td>\n",
       "      <td>{'@CAPEC_ID': '603', '@Nature': 'ChildOf', 'ns...</td>\n",
       "      <td>[{'@CWE_ID': '589'}, {'@CWE_ID': '227'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>97</td>\n",
       "      <td>Cryptanalysis is a process of finding weakness...</td>\n",
       "      <td>[{'@CAPEC_ID': '192', '@Nature': 'ChildOf'}, {...</td>\n",
       "      <td>[{'@CWE_ID': '327'}, {'@CWE_ID': '1240'}, {'@C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>98</td>\n",
       "      <td>Phishing is a social engineering technique whe...</td>\n",
       "      <td>[{'@CAPEC_ID': '151', '@Nature': 'ChildOf', 'n...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>527 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                        Description  \\\n",
       "0      1  In applications, particularly web applications...   \n",
       "1     10  This attack pattern involves causing a buffer ...   \n",
       "2    100  Buffer Overflow attacks target improper or mis...   \n",
       "3    101  An attacker can use Server Side Include (SSI) ...   \n",
       "4    102  Session sidejacking takes advantage of an unen...   \n",
       "..   ...                                                ...   \n",
       "522   94  This type of attack targets the communication ...   \n",
       "523   95  This attack targets the WSDL interface made av...   \n",
       "524   96  An application typically makes calls to functi...   \n",
       "525   97  Cryptanalysis is a process of finding weakness...   \n",
       "526   98  Phishing is a social engineering technique whe...   \n",
       "\n",
       "                                             rel_CAPEC  \\\n",
       "0    [{'@CAPEC_ID': '122', '@Nature': 'ChildOf'}, {...   \n",
       "1           {'@CAPEC_ID': '100', '@Nature': 'ChildOf'}   \n",
       "2           {'@CAPEC_ID': '123', '@Nature': 'ChildOf'}   \n",
       "3           {'@CAPEC_ID': '253', '@Nature': 'ChildOf'}   \n",
       "4           {'@CAPEC_ID': '593', '@Nature': 'ChildOf'}   \n",
       "..                                                 ...   \n",
       "522                                               None   \n",
       "523          {'@CAPEC_ID': '54', '@Nature': 'ChildOf'}   \n",
       "524  {'@CAPEC_ID': '603', '@Nature': 'ChildOf', 'ns...   \n",
       "525  [{'@CAPEC_ID': '192', '@Nature': 'ChildOf'}, {...   \n",
       "526  [{'@CAPEC_ID': '151', '@Nature': 'ChildOf', 'n...   \n",
       "\n",
       "                                               rel_CWE  \n",
       "0    [{'@CWE_ID': '276'}, {'@CWE_ID': '285'}, {'@CW...  \n",
       "1    [{'@CWE_ID': '120'}, {'@CWE_ID': '302'}, {'@CW...  \n",
       "2    [{'@CWE_ID': '120'}, {'@CWE_ID': '119'}, {'@CW...  \n",
       "3    [{'@CWE_ID': '97'}, {'@CWE_ID': '74'}, {'@CWE_...  \n",
       "4    [{'@CWE_ID': '294'}, {'@CWE_ID': '522'}, {'@CW...  \n",
       "..                                                 ...  \n",
       "522  [{'@CWE_ID': '300'}, {'@CWE_ID': '290'}, {'@CW...  \n",
       "523                                 {'@CWE_ID': '538'}  \n",
       "524           [{'@CWE_ID': '589'}, {'@CWE_ID': '227'}]  \n",
       "525  [{'@CWE_ID': '327'}, {'@CWE_ID': '1240'}, {'@C...  \n",
       "526                                               None  \n",
       "\n",
       "[527 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAPEC_df = pd.DataFrame(dict)\n",
    "CAPEC_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "certified-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create corpus from CAPEC descriptions\n",
    "corpus = ''\n",
    "counter = 0\n",
    "\n",
    "for desc in Desc:\n",
    "    try:\n",
    "        corpus += desc +'\\n'\n",
    "    except:\n",
    "        if desc:\n",
    "            corpus += desc['html:p'][0] +'\\n'\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "honest-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "emerging-history",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "TEXT                                              POS       DEP       \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dash = '-' * 80\n",
    "print(dash)\n",
    "print(\"{:<50}{:<10}{:<10}\".format(\"TEXT\", \"POS\", \"DEP\"))\n",
    "print(dash)\n",
    "for token in doc:\n",
    "    # Get the token text, part-of-speech tag and dependency label\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    # This is for formatting only\n",
    "    #print(f\"{token_text:<50}{token_pos:<10}{token_dep:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "according-hollywood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "TEXT                                              ENTITY    \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dash = '-' * 80\n",
    "print(dash)\n",
    "print(\"{:<50}{:<10}\".format(\"TEXT\", \"ENTITY\"))\n",
    "print(dash)    \n",
    "#for ent in doc.ents:\n",
    "#    # Print the entity text and its label\n",
    "#    print(f\"{ent.text:<50}{ent.label_:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "suitable-occasion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun phrases:\n"
     ]
    }
   ],
   "source": [
    "# Analyze syntax\n",
    "print(\"Noun phrases:\")\n",
    "#pp.pprint(set([chunk.text for chunk in doc.noun_chunks]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "heard-processing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbs:\n"
     ]
    }
   ],
   "source": [
    "print(\"Verbs:\")\n",
    "#pp.pprint(set([token.lemma_ for token in doc if token.pos_ == \"VERB\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "other-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"Data/CAPEC_descriptions.txt\", \"w\")\n",
    "text_file.write(corpus)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-temple",
   "metadata": {},
   "source": [
    "## Explore Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "satisfied-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-earth",
   "metadata": {},
   "source": [
    "## Remove stopwords, punctuation, and make lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aquatic-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))  \n",
    "\n",
    "word_tokens = word_tokenize(corpus.lower())\n",
    "  \n",
    "filtered_corpus = [w for w in word_tokens if not w in stop_words]  \n",
    "  \n",
    "filtered_corpus = []  \n",
    "  \n",
    "for w in word_tokens:  \n",
    "    if w not in stop_words and w.isalpha():  \n",
    "        filtered_corpus.append(w)  \n",
    "        \n",
    "#print(filtered_corpus) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-composite",
   "metadata": {},
   "source": [
    "## Make co-occurrence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hazardous-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import bigrams\n",
    "import itertools\n",
    "import pandas as pd\n",
    " \n",
    "def generate_co_occurrence_matrix(corpus):\n",
    "    vocab = set(corpus)\n",
    "    vocab = list(vocab)\n",
    "    vocab_index = {word: i for i, word in enumerate(vocab)}\n",
    " \n",
    "    # Create bigrams from all words in corpus\n",
    "    bi_grams = list(bigrams(corpus))\n",
    " \n",
    "    # Frequency distribution of bigrams ((word1, word2), num_occurrences)\n",
    "    bigram_freq = nltk.FreqDist(bi_grams).most_common(len(bi_grams))\n",
    " \n",
    "    # Initialise co-occurrence matrix\n",
    "    # co_occurrence_matrix[current][previous]\n",
    "    co_occurrence_matrix = np.zeros((len(vocab), len(vocab)))\n",
    " \n",
    "    # Loop through the bigrams taking the current and previous word,\n",
    "    # and the number of occurrences of the bigram.\n",
    "    for bigram in bigram_freq:\n",
    "        current = bigram[0][1]\n",
    "        previous = bigram[0][0]\n",
    "        count = bigram[1]\n",
    "        pos_current = vocab_index[current]\n",
    "        pos_previous = vocab_index[previous]\n",
    "        co_occurrence_matrix[pos_current][pos_previous] = count\n",
    "    co_occurrence_matrix = np.matrix(co_occurrence_matrix)\n",
    " \n",
    "    # return the matrix and the index\n",
    "    return co_occurrence_matrix, vocab_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "terminal-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, vocab_index = generate_co_occurrence_matrix(filtered_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "organic-hawaii",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                happens  fill  administrative  filters  symlinks  reluctance  \\\n",
      "happens             0.0   0.0             0.0      0.0       0.0         0.0   \n",
      "fill                0.0   0.0             0.0      0.0       0.0         0.0   \n",
      "administrative      0.0   0.0             0.0      0.0       0.0         0.0   \n",
      "filters             0.0   0.0             0.0      3.0       0.0         0.0   \n",
      "symlinks            0.0   0.0             0.0      0.0       0.0         0.0   \n",
      "...                 ...   ...             ...      ...       ...         ...   \n",
      "inherent            0.0   0.0             0.0      0.0       0.0         0.0   \n",
      "subvert             0.0   0.0             0.0      0.0       0.0         0.0   \n",
      "engineering         0.0   0.0             0.0      0.0       0.0         0.0   \n",
      "intelligent         0.0   0.0             0.0      0.0       0.0         0.0   \n",
      "circumvented        0.0   0.0             0.0      0.0       0.0         0.0   \n",
      "\n",
      "                ram  able  redirecting  receipt  ...  tracking  inject  \\\n",
      "happens         0.0   0.0          0.0      0.0  ...       0.0     0.0   \n",
      "fill            0.0   0.0          0.0      0.0  ...       0.0     0.0   \n",
      "administrative  0.0   0.0          0.0      0.0  ...       0.0     0.0   \n",
      "filters         0.0   0.0          0.0      0.0  ...       0.0     0.0   \n",
      "symlinks        0.0   0.0          0.0      0.0  ...       0.0     0.0   \n",
      "...             ...   ...          ...      ...  ...       ...     ...   \n",
      "inherent        0.0   0.0          0.0      0.0  ...       0.0     0.0   \n",
      "subvert         0.0   0.0          0.0      0.0  ...       0.0     0.0   \n",
      "engineering     0.0   0.0          0.0      0.0  ...       0.0     0.0   \n",
      "intelligent     0.0   0.0          0.0      0.0  ...       0.0     0.0   \n",
      "circumvented    0.0   0.0          0.0      0.0  ...       0.0     0.0   \n",
      "\n",
      "                attempting  search  sniffs  inherent  subvert  engineering  \\\n",
      "happens                0.0     0.0     0.0       0.0      0.0          0.0   \n",
      "fill                   0.0     0.0     0.0       0.0      0.0          0.0   \n",
      "administrative         0.0     0.0     0.0       0.0      0.0          0.0   \n",
      "filters                0.0     0.0     0.0       0.0      0.0          0.0   \n",
      "symlinks               0.0     0.0     0.0       0.0      0.0          0.0   \n",
      "...                    ...     ...     ...       ...      ...          ...   \n",
      "inherent               0.0     0.0     0.0       0.0      0.0          0.0   \n",
      "subvert                0.0     0.0     0.0       0.0      0.0          0.0   \n",
      "engineering            0.0     0.0     0.0       0.0      0.0          0.0   \n",
      "intelligent            0.0     0.0     0.0       0.0      0.0          0.0   \n",
      "circumvented           0.0     0.0     0.0       0.0      0.0          0.0   \n",
      "\n",
      "                intelligent  circumvented  \n",
      "happens                 0.0           0.0  \n",
      "fill                    0.0           0.0  \n",
      "administrative          0.0           0.0  \n",
      "filters                 0.0           0.0  \n",
      "symlinks                0.0           0.0  \n",
      "...                     ...           ...  \n",
      "inherent                0.0           0.0  \n",
      "subvert                 0.0           0.0  \n",
      "engineering             0.0           0.0  \n",
      "intelligent             0.0           0.0  \n",
      "circumvented            0.0           0.0  \n",
      "\n",
      "[4107 rows x 4107 columns]\n"
     ]
    }
   ],
   "source": [
    "data_matrix = pd.DataFrame(matrix, index=vocab_index,\n",
    "                             columns=vocab_index)\n",
    "print(data_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-dress",
   "metadata": {},
   "source": [
    "## Save co-occurrence matrix to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "surrounded-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix.to_csv('Data/CAPEC_coocurrence_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
