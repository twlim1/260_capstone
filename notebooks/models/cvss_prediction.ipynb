{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cy3yP6ZIqviO"
   },
   "source": [
    "**Title**: CVSS prediction\\\n",
    "**Description**: Load all pre-trained models to predict CVSS score. Runs on Google Collab\\\n",
    "**Developer**: Teck Lim\\\n",
    "**Created date**: 04/06/2021\\\n",
    "**Updated date**: 05/08/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ag-idHELBrp7"
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYRmeFrVSdLy",
    "outputId": "3ae71eda-96c3-40e6-bf88-78b5a66cd0ac"
   },
   "outputs": [],
   "source": [
    "# Install all the dependencies\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ahL6P2fCCihZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import textwrap\n",
    "\n",
    "from datetime import datetime\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error, mean_absolute_error\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rwzlHCCEC_K",
    "outputId": "a241e38e-ea14-4f9d-daf2-722f8ea1b234"
   },
   "outputs": [],
   "source": [
    "# Mount your google drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoCNVf7mgf52"
   },
   "source": [
    "# CVSS Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQLkil_lgfIe"
   },
   "outputs": [],
   "source": [
    "def round_up(input):\n",
    "    int_input = round(input * 100000)\n",
    "    if int_input % 10000 == 0:\n",
    "        return int_input / 100000.0\n",
    "    else:\n",
    "        return (math.floor(int_input / 10000) + 1) / 10.0\n",
    "\n",
    "def get_av_score(metric):\n",
    "    if metric == 'network':\n",
    "        return 0.85\n",
    "    elif metric == 'adjacent_network':\n",
    "        return 0.62\n",
    "    elif metric == 'local':\n",
    "        return 0.55\n",
    "    elif metric == 'physical':\n",
    "        return 0.20\n",
    "    else:\n",
    "        raise ValueError('Invalid metric value')\n",
    "\n",
    "def get_ac_score(metric):\n",
    "    if metric == 'low':\n",
    "        return 0.77\n",
    "    elif metric == 'high':\n",
    "        return 0.44\n",
    "    else:\n",
    "        raise ValueError('Invalid metric value')\n",
    "\n",
    "def get_pr_score(metric, s):\n",
    "    if metric == 'none':\n",
    "        return 0.85\n",
    "    elif metric == 'low':\n",
    "        return 0.68 if s == 'changed' else 0.62\n",
    "    elif metric == 'high':\n",
    "        return 0.50 if s == 'changed' else 0.27\n",
    "    else:\n",
    "        raise ValueError('Invalid metric value')\n",
    "\n",
    "def get_ui_score(metric):\n",
    "    if metric == 'none':\n",
    "        return 0.85\n",
    "    elif metric == 'required':\n",
    "        return 0.62\n",
    "    else:\n",
    "        raise ValueError('Invalid metric value')\n",
    "\n",
    "def get_c_score(metric):\n",
    "    if metric == 'high':\n",
    "        return 0.56\n",
    "    elif metric == 'low':\n",
    "        return 0.22\n",
    "    elif metric == 'none':\n",
    "        return 0\n",
    "    else:\n",
    "        raise ValueError('Invalid metric value')\n",
    "\n",
    "def get_i_score(metric):\n",
    "    if metric == 'high':\n",
    "        return 0.56\n",
    "    elif metric == 'low':\n",
    "        return 0.22\n",
    "    elif metric == 'none':\n",
    "        return 0\n",
    "    else:\n",
    "        raise ValueError('Invalid metric value')\n",
    "\n",
    "def get_a_score(metric):\n",
    "    if metric == 'high':\n",
    "        return 0.56\n",
    "    elif metric == 'low':\n",
    "        return 0.22\n",
    "    elif metric == 'none':\n",
    "        return 0\n",
    "    else:\n",
    "        raise ValueError('Invalid metric value')\n",
    "\n",
    "def calculcate_iss(c, i, a):\n",
    "    return 1 - (1-get_c_score(c)) * (1-get_i_score(i)) * (1-get_a_score(a))\n",
    "\n",
    "def calculate_impact(s, c, i, a):\n",
    "    iss = calculcate_iss(c, i, a)\n",
    "    if s == 'unchanged':\n",
    "        return 6.42 * iss\n",
    "    elif s == 'changed':\n",
    "        return (7.52 * (iss - 0.029)) - (3.25 * (iss - 0.02)**15)\n",
    "    else:\n",
    "        raise ValueError('Invalid metric value')\n",
    "\n",
    "def calculate_exploitability(av, ac, pr, ui, s):\n",
    "    return 8.22 * get_av_score(av) * get_ac_score(ac) * get_pr_score(pr, s) * get_ui_score(ui)\n",
    "\n",
    "def calculate_scores(av, ac, pr, ui, s, c, i, a):\n",
    "    av = av.lower()\n",
    "    ac = ac.lower()\n",
    "    pr = pr.lower()\n",
    "    ui = ui.lower()\n",
    "    s = s.lower()\n",
    "    c = c.lower()\n",
    "    i = i.lower()\n",
    "    a = a.lower()\n",
    "\n",
    "    impact = calculate_impact(s, c, i, a)\n",
    "    exploitability = calculate_exploitability(av, ac, pr, ui, s)\n",
    "    if impact <= 0:\n",
    "        base = 0\n",
    "    if s == 'unchanged':\n",
    "        base = min((impact + exploitability), 10)\n",
    "    elif s == 'changed':\n",
    "        base = min(1.08 * (impact + exploitability), 10)\n",
    "    return round_up(base), round(impact, 1), round(exploitability, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rw38cQVwgSQV",
    "outputId": "8ca01201-7b29-4196-9237-1baad7e038e0"
   },
   "outputs": [],
   "source": [
    "# Sample to validate the calculator\n",
    "calculate_scores('Network', 'High', 'Low', 'Required', 'Unchanged', 'Low', 'Low', 'Low')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwL07uCiCTvp"
   },
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9STRglRgSEu"
   },
   "outputs": [],
   "source": [
    "# The google drive needs to have cve_train.csv file to run the code\n",
    "file_path = './gdrive/Shareddrives/ucsd_drive/Data/cve_train.csv'\n",
    "df_train = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "054zFXp726s3"
   },
   "outputs": [],
   "source": [
    "# Validate the implemnted calculator. The calculated CVSS v3 base score should be the\n",
    "# same as provided score by NVD in CVE\n",
    "for idx, row in df_train.iterrows():\n",
    "    av = row['attack_vector'].lower()\n",
    "    ac = row['attack_complexity'].lower()\n",
    "    pr = row['privileges_required'].lower()\n",
    "    ui = row['user_interaction'].lower()\n",
    "    s = row['scope'].lower()\n",
    "    c = row['confidentiality'].lower()\n",
    "    i = row['integrity'].lower()\n",
    "    a = row['availability'].lower()\n",
    "    base_score = row['base_score']\n",
    "    exploitability_score = row['exploitability_score']\n",
    "    impact_score = row['impact_score']\n",
    "\n",
    "    try:\n",
    "        cal_base_score, cal_impact_score, cal_exploitability_score = calculate_scores(av, ac, pr, ui, s, c, i, a)\n",
    "    except Exception as e:\n",
    "        print('Index: {}, {}'.format(idx, row['cve_id']))\n",
    "        continue\n",
    "\n",
    "    # Print if calculated scores is different from provided scores\n",
    "    # Nothing should print if calculator is implemented correctly\n",
    "    if base_score != cal_base_score or exploitability_score != cal_exploitability_score or impact_score != cal_impact_score:\n",
    "        print('Index: {}, {}'.format(idx, row['cve_id']))\n",
    "        print('Base score: {}, {}'.format(base_score, cal_base_score))\n",
    "        print('Exploitability score: {}, {}'.format(exploitability_score, cal_exploitability_score))\n",
    "        print('Impact score: {}, {}'.format(impact_score, cal_impact_score))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Dt-gBnph8x5"
   },
   "source": [
    "# Load the pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZnR1safiibX"
   },
   "outputs": [],
   "source": [
    "# Network locations of all models\n",
    "av_output_dir = './gdrive/Shareddrives/ucsd_drive/Model/AV'\n",
    "ac_output_dir = './gdrive/Shareddrives/ucsd_drive/Model/AC'\n",
    "ui_output_dir = './gdrive/Shareddrives/ucsd_drive/Model/UI'\n",
    "pr_output_dir = './gdrive/Shareddrives/ucsd_drive/Model/PR'\n",
    "s_output_dir = './gdrive/Shareddrives/ucsd_drive/Model/SC'\n",
    "c_output_dir = './gdrive/Shareddrives/ucsd_drive/Model/CI'\n",
    "i_output_dir = './gdrive/Shareddrives/ucsd_drive/Model/II'\n",
    "a_output_dir = './gdrive/Shareddrives/ucsd_drive/Model/AI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nfv-OZTbkIxn",
    "outputId": "c7d9b565-5fac-4ca8-9126-af3f3dc9e680"
   },
   "outputs": [],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device('cuda')\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q93l4OZbDKbt",
    "outputId": "2c15afb6-c52e-49ba-b01d-2f17e06f9e45"
   },
   "outputs": [],
   "source": [
    "# Load all 8 models\n",
    "av_model = BertForSequenceClassification.from_pretrained(av_output_dir, output_hidden_states=True)\n",
    "av_tokenizer = BertTokenizer.from_pretrained(av_output_dir)\n",
    "av_model.to(device)\n",
    "\n",
    "ac_model = BertForSequenceClassification.from_pretrained(ac_output_dir, output_hidden_states=True)\n",
    "ac_tokenizer = BertTokenizer.from_pretrained(ac_output_dir)\n",
    "ac_model.to(device)\n",
    "\n",
    "pr_model = BertForSequenceClassification.from_pretrained(pr_output_dir, output_hidden_states=True)\n",
    "pr_tokenizer = BertTokenizer.from_pretrained(pr_output_dir)\n",
    "pr_model.to(device)\n",
    "\n",
    "ui_model = BertForSequenceClassification.from_pretrained(ui_output_dir, output_hidden_states=True)\n",
    "ui_tokenizer = BertTokenizer.from_pretrained(ui_output_dir)\n",
    "ui_model.to(device)\n",
    "\n",
    "s_model = BertForSequenceClassification.from_pretrained(s_output_dir, output_hidden_states=True)\n",
    "s_tokenizer = BertTokenizer.from_pretrained(s_output_dir)\n",
    "s_model.to(device)\n",
    "\n",
    "c_model = BertForSequenceClassification.from_pretrained(c_output_dir, output_hidden_states=True)\n",
    "c_tokenizer = BertTokenizer.from_pretrained(c_output_dir)\n",
    "c_model.to(device)\n",
    "\n",
    "i_model = BertForSequenceClassification.from_pretrained(i_output_dir, output_hidden_states=True)\n",
    "i_tokenizer = BertTokenizer.from_pretrained(i_output_dir)\n",
    "i_model.to(device)\n",
    "\n",
    "a_model = BertForSequenceClassification.from_pretrained(a_output_dir, output_hidden_states=True)\n",
    "a_tokenizer = BertTokenizer.from_pretrained(a_output_dir)\n",
    "a_model.to(device)\n",
    "\n",
    "print('All models loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o47Yj089ErNa"
   },
   "outputs": [],
   "source": [
    "def text_to_embedding(tokenizer, model, max_len, in_text):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        in_text,                      # Sentence to encode.\n",
    "                        add_special_tokens = True,    # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = max_len,         # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        # pad_to_max_length = True,\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True, # Construct attn. masks.\n",
    "                        return_tensors = 'pt',        # Return pytorch tensors.\n",
    "                    )\n",
    "    input_ids = encoded_dict['input_ids']\n",
    "    attn_mask = encoded_dict['attention_mask']\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    input_ids = input_ids.to(device)\n",
    "    attn_mask = attn_mask.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        result = model(input_ids=input_ids,\n",
    "                       token_type_ids=None,\n",
    "                       attention_mask=attn_mask,\n",
    "                       )\n",
    "\n",
    "    layer_i = 12\n",
    "    batch_i = 0\n",
    "    token_i = 0\n",
    "\n",
    "    logits = result.logits\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    vec = result.hidden_states[layer_i][batch_i][token_i]\n",
    "    vec = vec.detach().cpu().numpy()\n",
    "\n",
    "    return logits, vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qkCdBIViDNa"
   },
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oas42bj2R9qV"
   },
   "source": [
    "## Predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dsLAFPkAFGwm"
   },
   "outputs": [],
   "source": [
    "def print_custom(text, enabled=True):\n",
    "    if enabled:\n",
    "        print(text)\n",
    "\n",
    "def logit_2_confidence(logit):\n",
    "    return math.exp(logit) / (1 + math.exp(logit))\n",
    "\n",
    "def predict(input_text, confidence_threshold=None, enabled=True):\n",
    "    '''\n",
    "    input_text: description of cybersecurity\n",
    "    confidence_threshold: only return predicted metrics and scores if it is above threshold\n",
    "    enabled: print the details of each prediction\n",
    "    '''\n",
    "    wrapper = textwrap.TextWrapper(initial_indent='  ', subsequent_indent='  ', width=120)\n",
    "    print_custom('Description: \\n\\n{}'.format(wrapper.fill(input_text)), enabled)\n",
    "\n",
    "    print_custom('\\nPredictions:\\n', enabled)\n",
    "    logits, vec = text_to_embedding(av_tokenizer, av_model, 512, input_text)\n",
    "    if np.argmax(logits, axis=1) == 0:\n",
    "        pred_av = 'network'\n",
    "    elif np.argmax(logits, axis=1) == 1:\n",
    "        pred_av = 'adjacent_network'\n",
    "    elif np.argmax(logits, axis=1) == 2:\n",
    "        pred_av = 'local'\n",
    "    else:\n",
    "        pred_av = 'physical'\n",
    "    conf_av = logit_2_confidence(np.max(logits[0]))\n",
    "    print_custom('  AV: {}\\t\\tConfidence: {:.4f}'.format(pred_av.capitalize(), conf_av), enabled)\n",
    "    \n",
    "    logits, vec = text_to_embedding(ac_tokenizer, ac_model, 512, input_text)\n",
    "    if np.argmax(logits, axis=1) == 0:\n",
    "        pred_ac = 'low'\n",
    "    else:\n",
    "        pred_ac = 'high'\n",
    "    conf_ac = logit_2_confidence(np.max(logits[0]))\n",
    "    print_custom('  AC: {}\\t\\tConfidence: {:.4f}'.format(pred_ac.capitalize(), conf_ac), enabled)\n",
    "\n",
    "    logits, vec = text_to_embedding(pr_tokenizer, pr_model, 512, input_text)\n",
    "    if np.argmax(logits, axis=1) == 0:\n",
    "        pred_pr = 'none'\n",
    "    elif np.argmax(logits, axis=1) == 1:\n",
    "        pred_pr = 'low'\n",
    "    else:\n",
    "        pred_pr = 'high'\n",
    "    conf_pr = logit_2_confidence(np.max(logits[0]))\n",
    "    print_custom('  PR: {}\\t\\tConfidence: {:.4f}'.format(pred_pr.capitalize(), conf_pr), enabled)\n",
    "\n",
    "    logits, vec = text_to_embedding(ui_tokenizer, ui_model, 512, input_text)\n",
    "    if np.argmax(logits, axis=1) == 0:\n",
    "        pred_ui = 'none'\n",
    "    else:\n",
    "        pred_ui = 'required'\n",
    "    conf_ui = logit_2_confidence(np.max(logits[0]))\n",
    "    print_custom('  UI: {}\\t\\tConfidence: {:.4f}'.format(pred_ui.capitalize(), conf_ui), enabled)\n",
    "\n",
    "    logits, vec = text_to_embedding(s_tokenizer, s_model, 512, input_text)\n",
    "    if np.argmax(logits, axis=1) == 0:\n",
    "        pred_sc = 'unchanged'\n",
    "    else:\n",
    "        pred_sc = 'changed'\n",
    "    conf_sc = logit_2_confidence(np.max(logits[0]))\n",
    "    print_custom('  S : {}\\t\\tConfidence: {:.4f}'.format(pred_sc.capitalize(), conf_sc), enabled)\n",
    "\n",
    "    logits, vec = text_to_embedding(c_tokenizer, c_model, 512, input_text)\n",
    "    if np.argmax(logits, axis=1) == 0:\n",
    "        pred_ci = 'none'\n",
    "    elif np.argmax(logits, axis=1) == 1:\n",
    "        pred_ci = 'low'\n",
    "    else:\n",
    "        pred_ci = 'high'\n",
    "    conf_ci = logit_2_confidence(np.max(logits[0]))\n",
    "    print_custom('  C : {}\\t\\tConfidence: {:.4f}'.format(pred_ci.capitalize(), conf_ci), enabled)\n",
    "\n",
    "    logits, vec = text_to_embedding(i_tokenizer, i_model, 512, input_text)\n",
    "    if np.argmax(logits, axis=1) == 0:\n",
    "        pred_ii = 'none'\n",
    "    elif np.argmax(logits, axis=1) == 1:\n",
    "        pred_ii = 'low'\n",
    "    else:\n",
    "        pred_ii = 'high'\n",
    "    conf_ii = logit_2_confidence(np.max(logits[0]))\n",
    "    print_custom('  I : {}\\t\\tConfidence: {:.4f}'.format(pred_ii.capitalize(), conf_ii), enabled)\n",
    "\n",
    "    logits, vec = text_to_embedding(a_tokenizer, a_model, 512, input_text)\n",
    "    if np.argmax(logits, axis=1) == 0:\n",
    "        pred_ai = 'none'\n",
    "    elif np.argmax(logits, axis=1) == 1:\n",
    "        pred_ai = 'low'\n",
    "    else:\n",
    "        pred_ai = 'high'\n",
    "    conf_ai = logit_2_confidence(np.max(logits[0]))\n",
    "    print_custom('  A : {}\\t\\tConfidence: {:.4f}'.format(pred_ai.capitalize(), conf_ai), enabled)\n",
    "\n",
    "    pred_b, pred_i, pred_e = calculate_scores(pred_av, pred_ac, pred_pr, pred_ui, \n",
    "                                              pred_sc, pred_ci, pred_ii, pred_ai)\n",
    "    print_custom('', enabled)\n",
    "    print_custom('  Base score: {}'.format(pred_b), enabled)\n",
    "    print_custom('  Impact score: {}'.format(pred_i), enabled)\n",
    "    print_custom('  Exploitability score: {}'.format(pred_e), enabled)\n",
    "\n",
    "    if confidence_threshold:\n",
    "        if conf_av < confidence_threshold or conf_ac < confidence_threshold or\\\n",
    "            conf_pr < confidence_threshold or conf_ui < confidence_threshold or\\\n",
    "            conf_sc < confidence_threshold or conf_ci < confidence_threshold or\\\n",
    "            conf_ii < confidence_threshold or conf_ai < confidence_threshold:\n",
    "                return None, None\n",
    "    return (pred_b, pred_i, pred_e), (pred_av, pred_ac, pred_pr, pred_ui, pred_sc, pred_ci, pred_ii, pred_ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrpeBLMXNYPs"
   },
   "source": [
    "## Single input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QvPHaY52iH-V"
   },
   "outputs": [],
   "source": [
    "file_path = './gdrive/Shareddrives/ucsd_drive/Data/cve_test.csv'\n",
    "df_test = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiHuX8SQPBlc",
    "outputId": "c85c7dbf-e97e-4c06-cf8f-76297ed65760"
   },
   "outputs": [],
   "source": [
    "sample = df_test.sample(1)\n",
    "sample_text = sample.iloc[0]['description']\n",
    "\n",
    "(*_,) = predict(sample_text)\n",
    "\n",
    "print('')\n",
    "print('Truths:')\n",
    "print('')\n",
    "print('  AV: {}'.format(sample.iloc[0]['attack_vector'].capitalize()))\n",
    "print('  AC: {}'.format(sample.iloc[0]['attack_complexity'].capitalize()))\n",
    "print('  PR: {}'.format(sample.iloc[0]['privileges_required'].capitalize()))\n",
    "print('  UI: {}'.format(sample.iloc[0]['user_interaction'].capitalize()))\n",
    "print('  S : {}'.format(sample.iloc[0]['scope'].capitalize()))\n",
    "print('  C : {}'.format(sample.iloc[0]['confidentiality'].capitalize()))\n",
    "print('  I : {}'.format(sample.iloc[0]['integrity'].capitalize()))\n",
    "print('  A : {}'.format(sample.iloc[0]['availability'].capitalize()))\n",
    "print('')\n",
    "print('  Base score: {}'.format(sample.iloc[0]['base_score']))\n",
    "print('  Impact score: {}'.format(sample.iloc[0]['impact_score']))\n",
    "print('  Exploitability score: {}'.format(sample.iloc[0]['exploitability_score']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SB0z1gNMFFUe",
    "outputId": "356ffc4e-df9e-4af5-9b10-3233bde73e96"
   },
   "outputs": [],
   "source": [
    "input_text_1 = 'Sudo before 1.6.6 contains an off-by-one error that can result in a heap-based buffer overflow that may allow ' \\\n",
    "    'local users to gain root privileges via special characters in the -p (prompt) argument, which are not properly expanded.'\n",
    "input_text_2 = 'Ubiquiti Networks EdgeSwitch version 1.7.3 and prior suffer from an improperly neutralized element in an OS command ' \\\n",
    "    'due to lack of protection on the admin CLI, leading to code execution and privilege escalation greater than administrators themselves ' \\\n",
    "    'are allowed. An attacker with access to an admin account could escape the restricted CLI and execute arbitrary shell instructions.'\n",
    "input_text_3 = 'A \"javascript:\" url loaded by a malicious page can obfuscate its location by blanking the URL displayed in the addressbar, ' \\\n",
    "    'allowing for an attacker to spoof an existing page without the malicious page\\'s address being displayed correctly. This vulnerability affects Firefox < 52.'\n",
    "input_text_4 = 'Stack over flow that caused by typing long URL in chrome browser address'\n",
    "input_text_5 = 'For World Migratory Bird Day, we\\'re looking at a flock of black-tailed godwits in the Netherlands. These shorebirds breed in ' \\\n",
    "    'parts of Europe and Russia, and then migrate to areas in Western Europe, Africa, Asia, and Australia.'\n",
    "input_text_6 = 'A malicious unauthenticated user could abuse the lack of authentication check on a particular web service exposed by default ' \\\n",
    "    'in SAP Netweaver JAVA stack, allowing them to fully compromise the targeted system.'\n",
    "\n",
    "(pred_b, pred_i, pred_e), (pred_av, pred_ac, pred_pr, pred_ui, pred_s, pred_c, pred_i, pred_a) = predict(input_text_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWzuCNuuNcRF"
   },
   "source": [
    "## Batch input data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WPybSh1TNwkr",
    "outputId": "dcd09044-91d6-4588-ae8f-eef317650dad"
   },
   "outputs": [],
   "source": [
    "pred_b_labels = list()\n",
    "pred_i_labels = list()\n",
    "pred_e_labels = list()\n",
    "\n",
    "pred_av_labels = list()\n",
    "pred_ac_labels = list()\n",
    "pred_pr_labels = list()\n",
    "pred_ui_labels = list()\n",
    "pred_sc_labels = list()\n",
    "pred_ci_labels = list()\n",
    "pred_ii_labels = list()\n",
    "pred_ai_labels = list()\n",
    "\n",
    "pred_confidence = list()\n",
    "\n",
    "# Only output the predictions with threshold > .9. Uncomment it out to get all predictions\n",
    "# confidence_threshold = .9\n",
    "\n",
    "start_time = datetime.now()\n",
    "for idx, row in df_test.iterrows():\n",
    "    if (idx + 1) % 1000 == 0:\n",
    "        print('Processing index: {}'.format(idx + 1))\n",
    "        \n",
    "    scores, metrics = predict(row['description'], confidence_threshold, False)\n",
    "    if scores is None and metrics is None:\n",
    "        pred_confidence.append(False)\n",
    "        continue\n",
    "    else:\n",
    "        pred_confidence.append(True)\n",
    "\n",
    "    (b, i, e), (av, ac, pr, ui, sc, ci, ii, ai) = scores, metrics\n",
    "    pred_b_labels.append(b)\n",
    "    pred_i_labels.append(i)\n",
    "    pred_e_labels.append(e)\n",
    "\n",
    "    pred_av_labels.append(av)\n",
    "    pred_ac_labels.append(ac)\n",
    "    pred_pr_labels.append(pr)\n",
    "    pred_ui_labels.append(ui)\n",
    "    pred_sc_labels.append(sc)\n",
    "    pred_ci_labels.append(ci)\n",
    "    pred_ii_labels.append(ii)\n",
    "    pred_ai_labels.append(ai)\n",
    "\n",
    "print('Total time taken: {}s'.format((datetime.now() - start_time).seconds))\n",
    "print('Confidence threshold: {}'.format(confidence_threshold))\n",
    "print('Total Predicted: {}'.format(len(df_test)))\n",
    "print('Total above threshold: {}'.format(len(pred_b_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IvoL-6Dytwww"
   },
   "outputs": [],
   "source": [
    "df_test = df_test[pred_confidence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RK-eMZ3AOPnR",
    "outputId": "2d5846f1-b341-47aa-cf98-90fd9ee91d1d"
   },
   "outputs": [],
   "source": [
    "print('Metrics accuracy:')\n",
    "print('  AV (4-cat): {:.4f}'.format(accuracy_score(pred_av_labels, df_test['attack_vector'].apply(lambda x: x.lower()))))\n",
    "print('  AC (2-cat): {:.4f}'.format(accuracy_score(pred_ac_labels, df_test['attack_complexity'].apply(lambda x: x.lower()))))\n",
    "print('  PR (3-cat): {:.4f}'.format(accuracy_score(pred_pr_labels, df_test['privileges_required'].apply(lambda x: x.lower()))))\n",
    "print('  UI (2-cat): {:.4f}'.format(accuracy_score(pred_ui_labels, df_test['user_interaction'].apply(lambda x: x.lower()))))\n",
    "print('  S  (2-cat): {:.4f}'.format(accuracy_score(pred_sc_labels, df_test['scope'].apply(lambda x: x.lower()))))\n",
    "print('  C  (3-cat): {:.4f}'.format(accuracy_score(pred_ci_labels, df_test['confidentiality'].apply(lambda x: x.lower()))))\n",
    "print('  I  (3-cat): {:.4f}'.format(accuracy_score(pred_ii_labels, df_test['integrity'].apply(lambda x: x.lower()))))\n",
    "print('  A  (3-cat): {:.4f}'.format(accuracy_score(pred_ai_labels, df_test['availability'].apply(lambda x: x.lower()))))\n",
    "print('Exploitability score:')\n",
    "print('  MSE: {:.4f}'.format(mean_squared_error(pred_e_labels, df_test['exploitability_score'])))\n",
    "print('  MAE: {:.4f}'.format(mean_absolute_error(pred_e_labels, df_test['exploitability_score'])))\n",
    "print('  R2 : {:.4f}'.format(r2_score(pred_e_labels, df_test['exploitability_score'])))\n",
    "print('Impact score:')\n",
    "print('  MSE: {:.4f}'.format(mean_squared_error(pred_i_labels, df_test['impact_score'])))\n",
    "print('  MAE: {:.4f}'.format(mean_absolute_error(pred_i_labels, df_test['impact_score'])))\n",
    "print('  R2 : {:.4f}'.format(r2_score(pred_i_labels, df_test['impact_score'])))\n",
    "print('Base score:')\n",
    "print('  MSE: {:.4f}'.format(mean_squared_error(pred_b_labels, df_test['base_score'])))\n",
    "print('  MAE: {:.4f}'.format(mean_absolute_error(pred_b_labels, df_test['base_score'])))\n",
    "print('  R2 : {:.4f}'.format(r2_score(pred_b_labels, df_test['base_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21NxcFxyHGYF"
   },
   "outputs": [],
   "source": [
    "df_test.insert(loc=3, column='attack_vector_pred', value=[x.upper() for x in pred_av_labels])\n",
    "df_test.insert(loc=5, column='attack_complexity_pred', value=[x.upper() for x in pred_ac_labels])\n",
    "df_test.insert(loc=7, column='privileges_required_pred', value=[x.upper() for x in pred_pr_labels])\n",
    "df_test.insert(loc=9, column='user_interaction_pred', value=[x.upper() for x in pred_ui_labels])\n",
    "df_test.insert(loc=11, column='scope_pred', value=[x.upper() for x in pred_sc_labels])\n",
    "df_test.insert(loc=13, column='confidentiality_pred', value=[x.upper() for x in pred_ci_labels])\n",
    "df_test.insert(loc=15, column='integrity_pred', value=[x.upper() for x in pred_ii_labels])\n",
    "df_test.insert(loc=17, column='availability_pred', value=[x.upper() for x in pred_ai_labels])\n",
    "\n",
    "df_test.insert(loc=22, column='base_score_pred', value=pred_b_labels)\n",
    "df_test.insert(loc=24, column='exploitability_score_pred', value=pred_e_labels)\n",
    "df_test.insert(loc=26, column='impact_score_pred', value=pred_i_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ok5sZ1I9D2q"
   },
   "outputs": [],
   "source": [
    "test_results = './gdrive/Shareddrives/ucsd_drive/Data/cve_test_prediction_results.csv'\n",
    "df_test.to_csv(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "id": "XeR6msObEPcW",
    "outputId": "babaebb0-8b6a-48b1-f210-d91436965b46"
   },
   "outputs": [],
   "source": [
    "df_same = df_test[df_test.base_score == df_test.base_score_pred]\n",
    "\n",
    "df_high = df_test[df_test.base_score < df_test.base_score_pred]\n",
    "df_high_diff = df_high.base_score_pred - df_high.base_score\n",
    "print('Predicted value is higher by:')\n",
    "print('  Mean:    {:.4f}'.format(df_high_diff.mean()))\n",
    "print('  Std Dev: {:.4f}'.format(df_high_diff.std()))\n",
    "print('  Max:     {:.4f}'.format(df_high_diff.max()))\n",
    "print('  Min:     {:.4f}'.format(df_high_diff.min()))\n",
    "\n",
    "df_low = df_test[df_test.base_score > df_test.base_score_pred]\n",
    "df_low_diff = df_low.base_score - df_low.base_score_pred\n",
    "print('Predicted value is lower by:')\n",
    "print('  Mean:    {:.4f}'.format(df_low_diff.mean()))\n",
    "print('  Std Dev: {:.4f}'.format(df_low_diff.std()))\n",
    "print('  Max:     {:.4f}'.format(df_low_diff.max()))\n",
    "print('  Min:     {:.4f}'.format(df_low_diff.min()))\n",
    "\n",
    "df = pd.DataFrame({'lab':['Exact', 'Pred > Actual', 'Actual > Pred'], 'val':[df_same.shape[0], df_high.shape[0], df_low.shape[0]]})\n",
    "ax = df.plot.bar(x='lab', y='val', rot=0, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "Qk-2qAAADp4c",
    "outputId": "70b30e64-75b6-4522-cc02-495694bb2619"
   },
   "outputs": [],
   "source": [
    "df_hist = df_test.base_score - df_test.base_score_pred\n",
    "df_hist.hist(bins=20, figsize=(10,5));"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cvss_prediction.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
