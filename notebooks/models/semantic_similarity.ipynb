{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"semantic_similarity.ipynb","provenance":[{"file_id":"1JAnv99Nkrv-gfLzbicfjou0iXtdyjBpj","timestamp":1617779902224}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"cy3yP6ZIqviO"},"source":["**Title**: CVSS prediction\\\n","**Description**: Load all pre-trained models to predict CVSS score\\\n","**Developer**: Teck Lim\\\n","**Create date**: 04/06/2021"]},{"cell_type":"markdown","metadata":{"id":"ag-idHELBrp7"},"source":["# Import packages"]},{"cell_type":"code","metadata":{"id":"ahL6P2fCCihZ"},"source":["import os\n","import pandas as pd\n","import json\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","import textwrap\n","from google.colab import drive\n","\n","wrapper = textwrap.TextWrapper(initial_indent='  ', subsequent_indent='  ', width=120)\n","\n","!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1rwzlHCCEC_K"},"source":["drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lsPs8zOiiMke"},"source":["# Semantic similarity search"]},{"cell_type":"markdown","metadata":{"id":"KCAI21N8il4t"},"source":["## KNN"]},{"cell_type":"code","metadata":{"id":"tC_b9562G0G-"},"source":["!pip install faiss\n","!pip install faiss-gpu"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0wNm-5CJhGlp"},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device('cuda')\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device('cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pFJ9nSZClq9O"},"source":["file_path = './gdrive/Shareddrives/ucsd_drive/Data/cve.json'\n","with open(file_path, 'r') as fp:\n","    data = json.load(fp) \n","len(data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pd5w_GlNmAh4"},"source":["cve_id = list()\n","text = list()\n","for idx in range(len(data)):\n","    try:\n","          cve_id.append(data[idx]['cve']['CVE_data_meta']['ID'])\n","          text.append(' '.join([text['value'] for text in data[idx]['cve']['description']['description_data']]))\n","    except KeyError:\n","        print(idx)\n","        break\n","\n","df = pd.DataFrame({'cve_id': cve_id, 'text': text})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H9x_J5yomFqO"},"source":["sentences = df.text.values\n","len(sentences)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"norQpE4Ih6yp"},"source":["from transformers import BertForSequenceClassification, BertTokenizer\n","\n","ui_output_dir = './gdrive/Shareddrives/ucsd_drive/Model/UI'\n","ui_model = BertForSequenceClassification.from_pretrained(ui_output_dir, output_hidden_states=True)\n","ui_tokenizer = BertTokenizer.from_pretrained(ui_output_dir)\n","ui_model.to(device)\n","\n","pr_output_dir = './gdrive/Shareddrives/ucsd_drive/Model/PR'\n","pr_model = BertForSequenceClassification.from_pretrained(pr_output_dir, output_hidden_states=True)\n","pr_tokenizer = BertTokenizer.from_pretrained(pr_output_dir)\n","pr_model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o47Yj089ErNa"},"source":["import torch\n","def text_to_embedding(tokenizer, model, max_len, in_text):\n","    encoded_dict = tokenizer.encode_plus(\n","                        in_text,                      # Sentence to encode.\n","                        add_special_tokens = True,    # Add '[CLS]' and '[SEP]'\n","                        max_length = max_len,         # Pad & truncate all sentences.\n","                        padding='max_length',\n","                        # pad_to_max_length = True,\n","                        truncation=True,\n","                        return_attention_mask = True, # Construct attn. masks.\n","                        return_tensors = 'pt',        # Return pytorch tensors.\n","                    )\n","    input_ids = encoded_dict['input_ids']\n","    attn_mask = encoded_dict['attention_mask']\n","\n","    model.eval()\n","\n","    input_ids = input_ids.to(device)\n","    attn_mask = attn_mask.to(device)\n","\n","    with torch.no_grad():\n","        result = model(input_ids=input_ids,\n","                    token_type_ids=None,\n","                    attention_mask=attn_mask)\n","\n","    # print(result.hidden_states[12][0][0])\n","    layer_i = 12\n","    batch_i = 0\n","    token_i = 0\n","\n","    logits = result.logits\n","    logits = logits.detach().cpu().numpy()\n","\n","    vec = result.hidden_states[layer_i][batch_i][token_i]\n","    vec = vec.detach().cpu().numpy()\n","\n","    return logits, vec"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4rFhe-J2mKmj"},"source":["# vecs = list()\n","vecs_stacked = None\n","for idx, input_text in enumerate(sentences[:1000]):\n","    logits, vec = text_to_embedding(ui_tokenizer, ui_model, 512, input_text)\n","    vecs_stacked = vec if vecs_stacked is None else np.vstack((vecs_stacked, vec))\n","    # vecs.append(vec)\n","    if (idx + 1) % 1000 == 0:\n","        print('Processing index: {}'.format(idx + 1))\n","\n","print(vecs_stacked.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TceAMIE2i5j2"},"source":["# vecs = np.array(vecs)\n","ui_vecs = vecs_stacked\n","ui_vecs.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nQ5nKwyRGTRW"},"source":["# vecs = list()\n","vecs_stacked = None\n","for idx, input_text in enumerate(sentences[:1000]):\n","    logits, vec = text_to_embedding(pr_tokenizer, pr_model, 512, input_text)\n","    vecs_stacked = vec if vecs_stacked is None else np.vstack((vecs_stacked, vec))\n","    # vecs.append(vec)\n","    if (idx + 1) % 1000 == 0:\n","        print('Processing index: {}'.format(idx + 1))\n","\n","print(vecs_stacked.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rADI6kn4Gck5"},"source":["# vecs = np.array(vecs)\n","pr_vecs = vecs_stacked\n","pr_vecs.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sms7FWORlD5Y"},"source":["df_vectorized = pd.DataFrame(data=vecs_stacked)\n","df_vectorized.insert(loc=0, column='cve_id', value=df['cve_id'])\n","\n","save_path = './gdrive/Shareddrives/ucsd_drive/Data/cve_vectorized.csv'\n","df_vectorized.to_csv(save_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TF8LtY1KGqgS"},"source":["vecs = ui_vecs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a-1-KzUFi-vE"},"source":["import faiss\n","import time\n","\n","cpu_index = faiss.IndexFlatL2(vecs.shape[1])\n","\n","n_gpu = 1\n","\n","print('Number of GPU: {} using {}'.format(faiss.get_num_gpus(), n_gpu))\n","\n","co = faiss.GpuMultipleClonerOptions()\n","co.shard = True\n","\n","gpu_index = faiss.index_cpu_to_all_gpus(cpu_index, co=co, ngpu=n_gpu)\n","\n","t0 = time.time()\n","\n","gpu_index.add(vecs)\n","\n","elapsed = time.time() - t0\n","print('Building index took {} seconds'.format(elapsed))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6w8_UwurjdO8"},"source":["def find_top_3(input_text_vec):\n","  D, I = gpu_index.search(input_text_vec.reshape(1, 768), k=3)\n","\n","  print('Top 3 results')\n","\n","  for i in range(I.shape[1]):\n","    result_i = I[0, i]\n","    print(result_i)\n","    cve_id = df.iloc[result_i].cve_id\n","    text = df.iloc[result_i].text\n","\n","    print(wrapper.fill(cve_id))\n","    print(wrapper.fill('L2 distance: {}'.format(D[0, i])))\n","    print(wrapper.fill(text))\n","    print('')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0qc_WjOwOEjV"},"source":["sentences[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FhBTtvbpNxhe"},"source":["input_text_1 = 'Stack-based buffer overflow in the jpc_tsfb_getbands2 function in jpc_tsfb.c in JasPer before 1.900.30 allows ' \\\n","      'remote attackers to have unspecified impact via a crafted image.'\n","input_text_2 = 'Ubiquiti Networks EdgeSwitch version 1.7.3 and prior suffer from an improperly neutralized element in an OS command ' \\\n","      'due to lack of protection on the admin CLI, leading to code execution and privilege escalation greater than administrators themselves ' \\\n","      'are allowed. An attacker with access to an admin account could escape the restricted CLI and execute arbitrary shell instructions.'\n","input_text_3 = 'A \"javascript:\" url loaded by a malicious page can obfuscate its location by blanking the URL displayed in the addressbar, ' \\\n","      'allowing for an attacker to spoof an existing page without the malicious page\\'s address being displayed correctly. This vulnerability affects Firefox < 52.'\n","input_text_4 = \"stack over flow that caused by user inserting long text in chrome browser address url bar\"\n","input_text = input_text_1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlXrbd7oNca3"},"source":["logits, vec = text_to_embedding(pr_tokenizer, pr_model, 512, input_text)\n","find_top_3(vec)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RKjC-PXmHI_V"},"source":["logits, vec = text_to_embedding(ui_tokenizer, ui_model, 512, input_text)\n","find_top_3(vec)"],"execution_count":null,"outputs":[]}]}