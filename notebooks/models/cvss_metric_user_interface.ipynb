{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Title**: Model to predict CVSS **User Interface** metric\\\n",
    "**Description**: Model to predict CVSS **User Interface** metric. This notebook is intended to run on Google Collab\\\n",
    "**Developer**: Teck Lim\\\n",
    "**Create date**: 03/28/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tis2O1sxFrKs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MjpGriPWGPgN",
    "outputId": "71283b8b-a7f5-4dbc-bfb3-c4e43abc45e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.4.2\n",
    "!pip install wget==3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "C7hXe3WGGHrQ",
    "outputId": "acee1e03-fe82-42d4-b7cf-a890a06b466c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fhgbrTLGD5n",
    "outputId": "7e58d089-3122-44c4-b799-6e22be68f3c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yQ0pvg7yGNGL",
    "outputId": "e166930f-8658-448a-d79e-8c2179f1c5cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir: cannot access 'gdrive/MyDrive/Colab Notebooks/cve.json': Transport endpoint is not connected\n"
     ]
    }
   ],
   "source": [
    "!dir \"gdrive/MyDrive/Colab Notebooks/cve.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KqqtP4fMEW4n",
    "outputId": "9eb2997a-136f-4a4c-81ab-aec02cf0a356"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qtKyuCgIEW1z",
    "outputId": "613fd777-9f37-4c1a-86ab-1127c7fcfb31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zpOQh1meE_g4",
    "outputId": "b0ec3575-bbb6-44c6-92cb-39b29821f069"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150600"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'gdrive/MyDrive/Colab Notebooks/cve.json'\n",
    "with open(file_path, 'r') as fp:\n",
    "    data = json.load(fp) \n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "-uiBepstGh-O",
    "outputId": "e0d7502e-f9e9-47a6-c1ab-462dfd7f977c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Sudo before 1.6.6 contains an off-by-one error that can result in a heap-based buffer overflow that may allow local users to gain root privileges via special characters in the -p (prompt) argument, which are not properly expanded.'"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['cve']['description']['description_data'][0]['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "cDoXClbzGh6y",
    "outputId": "9bdd1476-92ed-4239-f07b-bbe70eafdd78"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'CVE-2002-0184'"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['cve']['CVE_data_meta']['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zszygF9YGhy-",
    "outputId": "f3c2e685-d8d9-42c3-9011-74dd36ca8f00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.9"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[10]['impact']['baseMetricV3']['impactScore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qTl84tpWGndo",
    "outputId": "e8f70b7c-0598-47a1-accb-7d7cc780305b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attackComplexity': 'LOW',\n",
       " 'attackVector': 'LOCAL',\n",
       " 'availabilityImpact': 'HIGH',\n",
       " 'baseScore': 7.8,\n",
       " 'baseSeverity': 'HIGH',\n",
       " 'confidentialityImpact': 'HIGH',\n",
       " 'integrityImpact': 'HIGH',\n",
       " 'privilegesRequired': 'NONE',\n",
       " 'scope': 'UNCHANGED',\n",
       " 'userInteraction': 'REQUIRED',\n",
       " 'vectorString': 'CVSS:3.1/AV:L/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H',\n",
       " 'version': '3.1'}"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[10]['impact']['baseMetricV3']['cvssV3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "PyHqq4VZEWoS"
   },
   "outputs": [],
   "source": [
    "text = list()\n",
    "label = list()\n",
    "for idx in range(len(data)):\n",
    "    try:\n",
    "        if data[idx].get('impact') and data[idx]['impact'].get('baseMetricV3'):   \n",
    "#             print('ID: {}'.format(data[idx]['cve']['CVE_data_meta']['ID']))\n",
    "#             for j, description in enumerate(data[idx]['cve']['description']['description_data']):\n",
    "#                 print('[{}]-{}'.format(j, description['value']))\n",
    "\n",
    "#             print('Impact Score: {}'.format(data[idx]['impact']['baseMetricV3']['impactScore']))\n",
    "#             print('Attack Complexity: {}'.format(data[idx]['impact']['baseMetricV3']['cvssV3']['userInteraction']))\n",
    "#             print('\\n')\n",
    "            text.append(' '.join([text['value'] for text in data[idx]['cve']['description']['description_data']]))\n",
    "            label.append(0 if data[idx]['impact']['baseMetricV3']['cvssV3']['userInteraction'] == 'NONE' else 1)\n",
    "    except KeyError:\n",
    "        print(idx)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o47Yj089ErNa",
    "outputId": "cf0a8ce9-b4c1-447c-92b3-9dfac1400ac3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77020, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'label': label, 'text': text})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "SB0z1gNMFFUe",
    "outputId": "f3f21c76-3e48-4ff9-8c39-b112429f70a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64467</th>\n",
       "      <td>0</td>\n",
       "      <td>Heap-based buffer overflow in drivers/net/macs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65566</th>\n",
       "      <td>0</td>\n",
       "      <td>Cab Booking Script 1.0 has SQL Injection via t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76239</th>\n",
       "      <td>0</td>\n",
       "      <td>JMS Client in IBM MessageSight 1.1.x through 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27845</th>\n",
       "      <td>0</td>\n",
       "      <td>During installation of an OpenShift 4 cluster,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40447</th>\n",
       "      <td>1</td>\n",
       "      <td>An elevation of privilege vulnerability in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41320</th>\n",
       "      <td>0</td>\n",
       "      <td>Mediawiki before 1.28.1 / 1.27.2 / 1.23.16 con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30897</th>\n",
       "      <td>0</td>\n",
       "      <td>The funced function in fish (aka fish-shell) 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38048</th>\n",
       "      <td>0</td>\n",
       "      <td>In Eclipse Mosquitto 1.4.14, a user can shutdo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74904</th>\n",
       "      <td>1</td>\n",
       "      <td>AppleRAID in Apple OS X before 10.11.4 allows ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35842</th>\n",
       "      <td>0</td>\n",
       "      <td>A CWE-248: Uncaught Exception vulnerability ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text\n",
       "64467      0  Heap-based buffer overflow in drivers/net/macs...\n",
       "65566      0  Cab Booking Script 1.0 has SQL Injection via t...\n",
       "76239      0  JMS Client in IBM MessageSight 1.1.x through 1...\n",
       "27845      0  During installation of an OpenShift 4 cluster,...\n",
       "40447      1  An elevation of privilege vulnerability in the...\n",
       "41320      0  Mediawiki before 1.28.1 / 1.27.2 / 1.23.16 con...\n",
       "30897      0  The funced function in fish (aka fish-shell) 1...\n",
       "38048      0  In Eclipse Mosquitto 1.4.14, a user can shutdo...\n",
       "74904      1  AppleRAID in Apple OS X before 10.11.4 allows ...\n",
       "35842      0  A CWE-248: Uncaught Exception vulnerability ex..."
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "SkhdDMXhNgfe",
    "outputId": "9e13383a-6025-4c46-9a6a-bdbb50cd4d85"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tmp = df.groupby('label').agg(['count']).reset_index()\n",
    "df_tmp.columns = ['label', 'count']\n",
    "df_tmp.plot(x='label', y='count', kind='bar', align='center', alpha=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "VPCK_f5uykdD",
    "outputId": "b4e706d8-08e4-4f25-f65d-5a268585f872"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tmp = df[:10000].groupby('label').agg(['count']).reset_index()\n",
    "df_tmp.columns = ['label', 'count']\n",
    "df_tmp.plot(x='label', y='count', kind='bar', align='center', alpha=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TduKyL6VGtQ3"
   },
   "outputs": [],
   "source": [
    "sentences = df.text.values\n",
    "labels = df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5NzB-wsNGwy_",
    "outputId": "49ff32b2-dba5-40b5-b27d-5b2907ce4e3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77020, 77020)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tC_b9562G0G-",
    "outputId": "b88615ba-1592-4479-ce25-fef721ab63f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Stack-based buffer overflow in the jpc_tsfb_getbands2 function in jpc_tsfb.c in JasPer before 1.900.30 allows remote attackers to have unspecified impact via a crafted image.',\n",
       " 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0], labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Teutu50XHynd"
   },
   "outputs": [],
   "source": [
    "sentences = sentences[:10000]\n",
    "labels = labels[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GW8IQTRkH66x",
    "outputId": "c5b89c4b-9390-43ad-fde4-9c6d56a6b2ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nl95EfNkH6wp",
    "outputId": "c22eb44b-5abe-40b5-d11f-b4def666ae5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Stack-based buffer overflow in the jpc_tsfb_getbands2 function in jpc_tsfb.c in JasPer before 1.900.30 allows remote attackers to have unspecified impact via a crafted image.',\n",
       " 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0], labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x0YBZcNtGy5X",
    "outputId": "cf4c3ac8-4f5e-4ed1-ce49-0ead2020e413"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_se4dJrG81F",
    "outputId": "05aec317-2e82-4aa3-c4f0-38293bbbc0bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  Stack-based buffer overflow in the jpc_tsfb_getbands2 function in jpc_tsfb.c in JasPer before 1.900.30 allows remote attackers to have unspecified impact via a crafted image.\n",
      "Tokenized:  ['stack', '-', 'based', 'buffer', 'over', '##flow', 'in', 'the', 'jp', '##c', '_', 'ts', '##fb', '_', 'get', '##band', '##s', '##2', 'function', 'in', 'jp', '##c', '_', 'ts', '##fb', '.', 'c', 'in', 'jasper', 'before', '1', '.', '900', '.', '30', 'allows', 'remote', 'attackers', 'to', 'have', 'unspecified', 'impact', 'via', 'a', 'crafted', 'image', '.']\n",
      "Token IDs:  [9991, 1011, 2241, 17698, 2058, 12314, 1999, 1996, 16545, 2278, 1035, 24529, 26337, 1035, 2131, 12733, 2015, 2475, 3853, 1999, 16545, 2278, 1035, 24529, 26337, 1012, 1039, 1999, 14791, 2077, 1015, 1012, 7706, 1012, 2382, 4473, 6556, 17857, 2000, 2031, 25851, 4254, 3081, 1037, 19275, 3746, 1012]\n"
     ]
    }
   ],
   "source": [
    "# Print the original sentence.\n",
    "print(' Original: ', sentences[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F2P3z8X-G8yX",
    "outputId": "eb54b22c-e46c-4996-d84f-90dc789a7452"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "52\n",
      "57\n",
      "81\n",
      "1197\n",
      "2175\n",
      "2848\n",
      "2853\n",
      "2945\n",
      "3034\n",
      "3036\n",
      "4057\n",
      "4624\n",
      "5163\n",
      "5166\n",
      "5167\n",
      "5168\n",
      "6103\n",
      "6815\n",
      "8075\n",
      "8079\n",
      "8083\n",
      "8092\n",
      "8492\n",
      "8496\n",
      "8511\n",
      "Max sentence length:  1672\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "# For every sentence...\n",
    "for i, sent in enumerate(sentences):\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "    if len(input_ids) > 512:\n",
    "      print(i)\n",
    "\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZl9aj1lG8vs",
    "outputId": "f18f7451-d4cf-4aa0-9d92-8581992ec629"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Stack-based buffer overflow in the jpc_tsfb_getbands2 function in jpc_tsfb.c in JasPer before 1.900.30 allows remote attackers to have unspecified impact via a crafted image.\n",
      "Token IDs: tensor([  101,  9991,  1011,  2241, 17698,  2058, 12314,  1999,  1996, 16545,\n",
      "         2278,  1035, 24529, 26337,  1035,  2131, 12733,  2015,  2475,  3853,\n",
      "         1999, 16545,  2278,  1035, 24529, 26337,  1012,  1039,  1999, 14791,\n",
      "         2077,  1015,  1012,  7706,  1012,  2382,  4473,  6556, 17857,  2000,\n",
      "         2031, 25851,  4254,  3081,  1037, 19275,  3746,  1012,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for i, sent in enumerate(sentences):\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 512,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "immdYPp9G8tH",
    "outputId": "b18e812d-946a-44ab-a018-f3cd988db011"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000, 10000)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids), len(attention_masks), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NQEkf_VbG8nz",
    "outputId": "0f7cbfc8-49b8-457c-e679-16e5c4595096"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9,000 training samples\n",
      "1,000 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "KWpbO54rG8lc"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 8\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KdeU14gyG8jD",
    "outputId": "738d5482-b910-469c-f844-9daec899eb09"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2VUYUaM7G8gd",
    "outputId": "ce203b0e-24d2-4ab8-e385-5010ed4ada54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "KegQ7yYdG8dl"
   },
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Y7GskjurG8as"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 2\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "l9p6aHYyG8Xd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "kFhdUkq1G8NL"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71NrnZIHK_Fl",
    "outputId": "f82eca80-4909-4ec3-92fa-084c20b98f37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of  1,125.    Elapsed: 0:00:30.\n",
      "  Batch    80  of  1,125.    Elapsed: 0:01:00.\n",
      "  Batch   120  of  1,125.    Elapsed: 0:01:30.\n",
      "  Batch   160  of  1,125.    Elapsed: 0:02:01.\n",
      "  Batch   200  of  1,125.    Elapsed: 0:02:33.\n",
      "  Batch   240  of  1,125.    Elapsed: 0:03:04.\n",
      "  Batch   280  of  1,125.    Elapsed: 0:03:36.\n",
      "  Batch   320  of  1,125.    Elapsed: 0:04:08.\n",
      "  Batch   360  of  1,125.    Elapsed: 0:04:40.\n",
      "  Batch   400  of  1,125.    Elapsed: 0:05:12.\n",
      "  Batch   440  of  1,125.    Elapsed: 0:05:44.\n",
      "  Batch   480  of  1,125.    Elapsed: 0:06:16.\n",
      "  Batch   520  of  1,125.    Elapsed: 0:06:48.\n",
      "  Batch   560  of  1,125.    Elapsed: 0:07:20.\n",
      "  Batch   600  of  1,125.    Elapsed: 0:07:52.\n",
      "  Batch   640  of  1,125.    Elapsed: 0:08:25.\n",
      "  Batch   680  of  1,125.    Elapsed: 0:08:57.\n",
      "  Batch   720  of  1,125.    Elapsed: 0:09:29.\n",
      "  Batch   760  of  1,125.    Elapsed: 0:10:01.\n",
      "  Batch   800  of  1,125.    Elapsed: 0:10:34.\n",
      "  Batch   840  of  1,125.    Elapsed: 0:11:06.\n",
      "  Batch   880  of  1,125.    Elapsed: 0:11:38.\n",
      "  Batch   920  of  1,125.    Elapsed: 0:12:10.\n",
      "  Batch   960  of  1,125.    Elapsed: 0:12:43.\n",
      "  Batch 1,000  of  1,125.    Elapsed: 0:13:15.\n",
      "  Batch 1,040  of  1,125.    Elapsed: 0:13:47.\n",
      "  Batch 1,080  of  1,125.    Elapsed: 0:14:20.\n",
      "  Batch 1,120  of  1,125.    Elapsed: 0:14:52.\n",
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epcoh took: 0:14:56\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.93\n",
      "  Validation Loss: 0.24\n",
      "  Validation took: 0:00:37\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of  1,125.    Elapsed: 0:00:32.\n",
      "  Batch    80  of  1,125.    Elapsed: 0:01:05.\n",
      "  Batch   120  of  1,125.    Elapsed: 0:01:37.\n",
      "  Batch   160  of  1,125.    Elapsed: 0:02:09.\n",
      "  Batch   200  of  1,125.    Elapsed: 0:02:41.\n",
      "  Batch   240  of  1,125.    Elapsed: 0:03:13.\n",
      "  Batch   280  of  1,125.    Elapsed: 0:03:45.\n",
      "  Batch   320  of  1,125.    Elapsed: 0:04:17.\n",
      "  Batch   360  of  1,125.    Elapsed: 0:04:50.\n",
      "  Batch   400  of  1,125.    Elapsed: 0:05:22.\n",
      "  Batch   440  of  1,125.    Elapsed: 0:05:54.\n",
      "  Batch   480  of  1,125.    Elapsed: 0:06:26.\n",
      "  Batch   520  of  1,125.    Elapsed: 0:06:58.\n",
      "  Batch   560  of  1,125.    Elapsed: 0:07:30.\n",
      "  Batch   600  of  1,125.    Elapsed: 0:08:03.\n",
      "  Batch   640  of  1,125.    Elapsed: 0:08:35.\n",
      "  Batch   680  of  1,125.    Elapsed: 0:09:07.\n",
      "  Batch   720  of  1,125.    Elapsed: 0:09:39.\n",
      "  Batch   760  of  1,125.    Elapsed: 0:10:11.\n",
      "  Batch   800  of  1,125.    Elapsed: 0:10:43.\n",
      "  Batch   840  of  1,125.    Elapsed: 0:11:15.\n",
      "  Batch   880  of  1,125.    Elapsed: 0:11:47.\n",
      "  Batch   920  of  1,125.    Elapsed: 0:12:19.\n",
      "  Batch   960  of  1,125.    Elapsed: 0:12:52.\n",
      "  Batch 1,000  of  1,125.    Elapsed: 0:13:24.\n",
      "  Batch 1,040  of  1,125.    Elapsed: 0:13:56.\n",
      "  Batch 1,080  of  1,125.    Elapsed: 0:14:28.\n",
      "  Batch 1,120  of  1,125.    Elapsed: 0:15:01.\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 0:15:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94\n",
      "  Validation Loss: 0.26\n",
      "  Validation took: 0:00:36\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:31:14 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
    "        # function and pass down the arguments. The `forward` function is \n",
    "        # documented here: \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
    "        # The results are returned in a results object, documented here:\n",
    "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
    "        # Specifically, we'll get the loss (because we provided labels) and the\n",
    "        # \"logits\"--the model outputs prior to activation.\n",
    "        result = model(b_input_ids, \n",
    "                       token_type_ids=None, \n",
    "                       attention_mask=b_input_mask, \n",
    "                       labels=b_labels,\n",
    "                       return_dict=True)\n",
    "\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            result = model(b_input_ids, \n",
    "                           token_type_ids=None, \n",
    "                           attention_mask=b_input_mask,\n",
    "                           labels=b_labels,\n",
    "                           return_dict=True)\n",
    "\n",
    "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
    "        # output values prior to applying an activation function like the \n",
    "        # softmax.\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "5E4u8SsaLALy",
    "outputId": "07dbb6ed-8247-4509-81fe-9378edf34f69"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0:14:56</td>\n",
       "      <td>0:00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0:15:05</td>\n",
       "      <td>0:00:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.34         0.24           0.93       0:14:56         0:00:37\n",
       "2               0.21         0.26           0.94       0:15:05         0:00:36"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "nYWR70rYLCMO",
    "outputId": "b2e58c87-2bb4-4dfb-ac4a-792058619350"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "FMTsXhxYLCKB"
   },
   "outputs": [],
   "source": [
    "sentences = df.text.values\n",
    "labels = df.label.values\n",
    "\n",
    "# Create sentence and label lists\n",
    "sentences = sentences[10000:12000]\n",
    "labels = labels[10000:12000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mxnqzv5FZVwT",
    "outputId": "3f79e605-7335-4753-a7e9-aea373c59d55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2000)"
      ]
     },
     "execution_count": 112,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQrzgSWsLCHx",
    "outputId": "338c5d80-2a14-40bc-e1e3-10b3fccb9a45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 2,000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# Report the number of sentences.\n",
    "print('Number of test sentences: {:,}\\n'.format(len(sentences)))\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 512,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 8  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KB0NTyycLCFR",
    "outputId": "ece4b7a0-cb77-4671-c9f4-4bbaa3d54db8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 2,000 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions.\n",
    "      result = model(b_input_ids, \n",
    "                     token_type_ids=None, \n",
    "                     attention_mask=b_input_mask,\n",
    "                     return_dict=True)\n",
    "\n",
    "  logits = result.logits\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjhn87GPLCCu",
    "outputId": "18993ba2-9c64-471f-8271-b1602d9d49ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 27624 of 77020 (35.87%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wd9BP7bULCAK",
    "outputId": "2ee70855-be3c-44ff-d347-2b70ea32c6dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 524 of 2000 (26.20%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.label[10000:12000].sum(), len(df.label[10000:12000]), (df.label[10000:12000].sum() / len(df.label[10000:12000]) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F_1jWRqGLAgr",
    "outputId": "14ec5a85-b3f7-4175-de7f-5366debc969c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 250)"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "len(predictions), len(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XSNerxViiIuZ",
    "outputId": "a8fa6e16-cf26-4a87-8a2a-12d5c609740c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 1, 1, 0, 0, 0, 1]), array([0, 1, 1, 1, 0, 0, 0, 1]))"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 120\n",
    "np.argmax(predictions[i], axis=1).flatten(), true_labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RDKz0brwjSBs",
    "outputId": "f54858e8-3041-4506-a06f-15f90393d7cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "Accuracy: 0.9155, Count: 1831\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Combine the results across all batches. \n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "print(len(flat_true_labels))\n",
    "\n",
    "accuracy = accuracy_score(flat_true_labels, flat_predictions)\n",
    "count = accuracy_score(flat_true_labels, flat_predictions, normalize=False)\n",
    "\n",
    "print('Accuracy: {}, Count: {}'.format(accuracy, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JN2iTFcHjR-O"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RUio3xdajR7P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ngHQKxSdjRyo",
    "outputId": "0be4bddb-793a-4c8e-9928-be010480c8f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./model_save/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./model_save/tokenizer_config.json',\n",
       " './model_save/special_tokens_map.json',\n",
       " './model_save/vocab.txt',\n",
       " './model_save/added_tokens.json')"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "output_dir = './model_save/'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Good practice: save your training arguments together with the trained model\n",
    "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zVwnGKRjlKp5",
    "outputId": "6d3e7c3c-3b32-49a7-ec25-1dc253a92d98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 428004K\n",
      "-rw-r--r-- 1 root root      1K Mar 21 20:57 config.json\n",
      "-rw-r--r-- 1 root root 427759K Mar 21 20:57 pytorch_model.bin\n",
      "-rw-r--r-- 1 root root      1K Mar 21 20:57 special_tokens_map.json\n",
      "-rw-r--r-- 1 root root      1K Mar 21 20:57 tokenizer_config.json\n",
      "-rw-r--r-- 1 root root    227K Mar 21 20:57 vocab.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -l --block-size=K ./model_save/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "5XGiCkYplQJl"
   },
   "outputs": [],
   "source": [
    "# Copy the model files to a directory in your Google Drive.\n",
    "!cp -r ./model_save/ \"./gdrive/MyDrive/Colab Notebooks/bert_ui/\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT_UI.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
