{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "raising-indiana",
   "metadata": {},
   "source": [
    "## CVE Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "collected-knitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#import pandas as pd\n",
    "#import urllib.request\n",
    "#import xml.etree.ElementTree as ET\n",
    "#import xmltodict\n",
    "#import spacy\n",
    "import numpy as np\n",
    "import nltk\n",
    "#import itertools\n",
    "from nltk import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-designation",
   "metadata": {},
   "source": [
    "## Load CVE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "brief-leave",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/all_CVE_data.json') as f:\n",
    "    cve_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-garage",
   "metadata": {},
   "source": [
    "## Get CVE Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "august-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "cve_desc_list = []\n",
    "\n",
    "# About 202,000 Items\n",
    "file_name = 'Data/all_CVE_descriptions.txt'\n",
    "with open(file_name, 'w') as f:\n",
    "    for i in range(len(cve_dict['cve']['item'])):\n",
    "        cve_desc_list.append(cve_dict['cve']['item'][i]['desc'])\n",
    "        f.write(cve_dict['cve']['item'][i]['desc'] +'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-cleaners",
   "metadata": {},
   "source": [
    "## Generate corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "enclosed-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create corpus from CVE descriptions\n",
    "corpus = ''\n",
    "\n",
    "for desc in cve_desc_list:\n",
    "    try:\n",
    "        corpus += desc + ' '\n",
    "    except:\n",
    "        if desc:\n",
    "            corpus += desc['html:p'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-active",
   "metadata": {},
   "source": [
    "## Remove stopwords, punctuation, and make lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "collected-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))  \n",
    "\n",
    "word_tokens = word_tokenize(corpus.lower())\n",
    "  \n",
    "filtered_corpus = [w for w in word_tokens if not w in stop_words]  \n",
    "  \n",
    "filtered_corpus = []  \n",
    "  \n",
    "for w in word_tokens:  \n",
    "    if w not in stop_words and w.isalpha():  \n",
    "        filtered_corpus.append(w)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-pottery",
   "metadata": {},
   "source": [
    "## Function to make co-occurrence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "valid-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_co_occurrence_matrix(corpus,window):\n",
    "    vocab = set(corpus)\n",
    "    vocab = list(vocab)\n",
    "    vocab_index = {word: i for i, word in enumerate(vocab)}\n",
    " \n",
    "    # Create bigrams from all words in corpus\n",
    "    #bi_grams = list(bigrams(corpus))\n",
    "    #print(bi_grams[0:10])\n",
    "    \n",
    "    # Ivan - Modification - Window N\n",
    "    print('[START] Create word pairs')\n",
    "    N_grams = []\n",
    "    for i in range(len(corpus)):\n",
    "        for j in range(1,N+1):\n",
    "            if i+j<len(corpus):\n",
    "                N_grams.append((corpus[i],corpus[i+j]))\n",
    "            if i-j>=0:\n",
    "                N_grams.append((corpus[i],corpus[i-j]))\n",
    "    print('[COMPLETE] Create word pairs')\n",
    "    # Frequency distribution of bigrams ((word1, word2), num_occurrences)\n",
    "    print('[START] Calculate number of occurrences')\n",
    "    ngram_freq = nltk.FreqDist(N_grams).most_common(len(N_grams))\n",
    "    print('[COMPLETE] Calculate number of occurrences')\n",
    "    # Initialise co-occurrence matrix\n",
    "    # co_occurrence_matrix[current][previous]\n",
    "    co_occurrence_matrix = np.zeros((len(vocab), len(vocab)))\n",
    " \n",
    "    # Loop through the bigrams taking the current and previous word,\n",
    "    # and the number of occurrences of the bigram.\n",
    "    print('[START] Generate Co-occurrence Matrix')\n",
    "    for ngram in ngram_freq:\n",
    "        current = ngram[0][1]\n",
    "        previous = ngram[0][0]\n",
    "        count = ngram[1]\n",
    "        pos_current = vocab_index[current]\n",
    "        pos_previous = vocab_index[previous]\n",
    "        co_occurrence_matrix[pos_current][pos_previous] = count\n",
    "    co_occurrence_matrix = np.matrix(co_occurrence_matrix)\n",
    "    print('[COMPLETE] Generate Co-occurrence Matrix')\n",
    "    \n",
    "    # return the matrix and the index\n",
    "    return co_occurrence_matrix, vocab_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-comfort",
   "metadata": {},
   "source": [
    "## Generate co-occurrence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "recent-surrey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] Create word pairs\n",
      "[COMPLETE] Create word pairs\n",
      "4321275\n",
      "43212720\n",
      "[START] Calculate number of occurrences\n",
      "[COMPLETE] Calculate number of occurrences\n",
      "[START] Generate Co-occurrence Matrix\n",
      "[COMPLETE] Generate Co-occurrence Matrix\n"
     ]
    }
   ],
   "source": [
    "matrix, vocab_index = generate_co_occurrence_matrix(filtered_corpus,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "national-router",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       bevywise  team  zaptel  joomlapraise  fledrcms  cuve  \\\n",
      "bevywise                    0.0   0.0     0.0           0.0       0.0   0.0   \n",
      "team                        0.0   4.0     0.0           0.0       0.0   0.0   \n",
      "zaptel                      0.0   0.0     0.0           0.0       0.0   0.0   \n",
      "joomlapraise                0.0   0.0     0.0           0.0       0.0   0.0   \n",
      "fledrcms                    0.0   0.0     0.0           0.0       0.0   0.0   \n",
      "...                         ...   ...     ...           ...       ...   ...   \n",
      "processors                  0.0   0.0     0.0           0.0       0.0   0.0   \n",
      "pami                        0.0   0.0     0.0           0.0       0.0   0.0   \n",
      "importgrayquantumtype       0.0   0.0     0.0           0.0       0.0   0.0   \n",
      "ragged                      0.0   0.0     0.0           0.0       0.0   0.0   \n",
      "benefit                     0.0   0.0     0.0           0.0       0.0   0.0   \n",
      "\n",
      "                       module  hasxdmxauth  simultaneous  uresk  ...  conoces  \\\n",
      "bevywise                  0.0          0.0           0.0    0.0  ...      0.0   \n",
      "team                      0.0          0.0           0.0    0.0  ...      0.0   \n",
      "zaptel                    0.0          0.0           0.0    0.0  ...      0.0   \n",
      "joomlapraise              0.0          0.0           0.0    0.0  ...      0.0   \n",
      "fledrcms                  0.0          0.0           0.0    0.0  ...      0.0   \n",
      "...                       ...          ...           ...    ...  ...      ...   \n",
      "processors                2.0          0.0           1.0    0.0  ...      0.0   \n",
      "pami                      0.0          0.0           0.0    0.0  ...      0.0   \n",
      "importgrayquantumtype     0.0          0.0           0.0    0.0  ...      0.0   \n",
      "ragged                    0.0          0.0           0.0    0.0  ...      0.0   \n",
      "benefit                   0.0          0.0           0.0    0.0  ...      0.0   \n",
      "\n",
      "                       libbzrtp  swftc  xenvironment  vitalnet  processors  \\\n",
      "bevywise                    0.0    0.0           0.0       0.0         0.0   \n",
      "team                        0.0    0.0           0.0       0.0         0.0   \n",
      "zaptel                      0.0    0.0           0.0       0.0         0.0   \n",
      "joomlapraise                0.0    0.0           0.0       0.0         0.0   \n",
      "fledrcms                    0.0    0.0           0.0       0.0         0.0   \n",
      "...                         ...    ...           ...       ...         ...   \n",
      "processors                  0.0    0.0           0.0       0.0        14.0   \n",
      "pami                        0.0    0.0           0.0       0.0         0.0   \n",
      "importgrayquantumtype       0.0    0.0           0.0       0.0         0.0   \n",
      "ragged                      0.0    0.0           0.0       0.0         0.0   \n",
      "benefit                     0.0    0.0           0.0       0.0         0.0   \n",
      "\n",
      "                       pami  importgrayquantumtype  ragged  benefit  \n",
      "bevywise                0.0                    0.0     0.0      0.0  \n",
      "team                    0.0                    0.0     0.0      0.0  \n",
      "zaptel                  0.0                    0.0     0.0      0.0  \n",
      "joomlapraise            0.0                    0.0     0.0      0.0  \n",
      "fledrcms                0.0                    0.0     0.0      0.0  \n",
      "...                     ...                    ...     ...      ...  \n",
      "processors              0.0                    0.0     0.0      0.0  \n",
      "pami                    0.0                    0.0     0.0      0.0  \n",
      "importgrayquantumtype   0.0                    0.0     0.0      0.0  \n",
      "ragged                  0.0                    0.0     0.0      0.0  \n",
      "benefit                 0.0                    0.0     0.0      0.0  \n",
      "\n",
      "[64182 rows x 64182 columns]\n"
     ]
    }
   ],
   "source": [
    "data_matrix = pd.DataFrame(matrix, index=vocab_index,\n",
    "                             columns=vocab_index)\n",
    "print(data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "assisted-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "foster-college",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-e8f640920938>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/CVE_coocurrence_matrix.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3400\u001b[0m             \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3401\u001b[0m             \u001b[0mescapechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mescapechar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3402\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3403\u001b[0m         )\n\u001b[1;32m   3404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         )\n\u001b[0;32m-> 1083\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m             )\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_need_to_save_header\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstart_i\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_matrix.to_csv('Data/CVE_coocurrence_matrix.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
